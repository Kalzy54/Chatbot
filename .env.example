# ============================================================================
# MewarChat Configuration - Optimized for Maximum Functionality
# ============================================================================
# Copy this file to .env and update the values for your environment.

# OpenAI API Configuration
# Required: Your OpenAI API key for GPT-4o-mini LLM calls
OPENAI_API_KEY=sk-your-api-key-here

# RAG Embedding Model Configuration
# EMBEDDING_MODEL: Sentence transformer model for semantic search
# Options (ranked by quality/speed):
#   - all-mpnet-base-v2 (RECOMMENDED - best accuracy for English/mixed content, ~430MB)
#   - all-MiniLM-L12-v2 (fast, decent quality, ~80MB) - use for resource constraints
#   - paraphrase-multilingual-mpnet-base-v2 (best for multilingual, ~430MB)
#   - multilingual-e5-large (excellent multilingual, largest, ~1.2GB)
# Default: all-mpnet-base-v2 (best general-purpose option)
EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2

# Chunking Configuration
# CHUNK_SIZE_TOKENS: Size of text chunks for embedding (larger = more context preserved)
# Default: 900 tokens (~3600 characters) - optimal for RAG balance
# Increase (1200+) if docs have long-form prose; decrease (600) if highly structured
CHUNK_SIZE_TOKENS=900

# CHUNK_OVERLAP_TOKENS: Token overlap between chunks to maintain context flow
# Default: 300 tokens - increased from 200 for better semantic continuity
# Higher values ensure smoother retrieve/answer transitions at chunk boundaries
CHUNK_OVERLAP_TOKENS=300

# Retrieval Configuration
# SIMILARITY_THRESHOLD: Minimum cosine similarity score (0.0-1.0) to accept retrieved docs
# Default: 0.35 - filters low-relevance results
# Lower (0.15-0.25) = retrieve more docs but risk noise
# Higher (0.5+) = retrieve fewer but high-confidence docs only
SIMILARITY_THRESHOLD=0.35

# TOP_K: Number of chunks to retrieve per query
# Default: 8 - provides comprehensive context while managing token budget
# Increase to 10-15 if using longer max_tokens in LLM; decrease to 3-5 for speed
TOP_K=8

# Web Scraping Configuration (Optional)
# UNIVERSITY_WEB_URL: Base URL of university/library website to crawl for knowledge base
# Leave blank to use local documents in data/ folder
# Example: https://library.youruni.edu/
# Example: https://miu.edu.ng/
UNIVERSITY_WEB_URL=

# Admin Credentials (for Streamlit UI)
# Used for admin panel access in streamlit_app.py
ADMIN_USERNAME=admin
ADMIN_PASSWORD=libraryChat2026

# ============================================================================
# PERFORMANCE TUNING GUIDE
# ============================================================================
# For MAXIMUM QUALITY (more memory/time):
#   EMBEDDING_MODEL=sentence-transformers/multilingual-e5-large
#   CHUNK_SIZE_TOKENS=1200
#   CHUNK_OVERLAP_TOKENS=400
#   SIMILARITY_THRESHOLD=0.30
#   TOP_K=10

# For BALANCED (recommended):
#   EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
#   CHUNK_SIZE_TOKENS=900
#   CHUNK_OVERLAP_TOKENS=300
#   SIMILARITY_THRESHOLD=0.35
#   TOP_K=8

# For RESOURCE-CONSTRAINED (less memory/faster):
#   EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L12-v2
#   CHUNK_SIZE_TOKENS=600
#   CHUNK_OVERLAP_TOKENS=150
#   SIMILARITY_THRESHOLD=0.40
#   TOP_K=5
#   (Also set SKIP_INGEST_ON_STARTUP=1 and start backend with --workers 1)
